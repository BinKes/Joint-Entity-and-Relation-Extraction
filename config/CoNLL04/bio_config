#dataset
filename_dev = "data/CoNLL04/dev.txt"
filename_test = "data/CoNLL04/test.txt"
filename_train = "data/CoNLL04/train.txt"

filename_train_me = "data/CoNLL04/train_me.json"
filename_dev_me = "data/CoNLL04/dev_me.json"
filename_test_me = "data/CoNLL04/test_me.json"

filename_char2id = "data/CoNLL04/char2id.json"
filename_word2id = "data/CoNLL04/word2id.json"
filename_n_char2id = "data/CoNLL04/n_char2id.json"
filename_BIO2id = "data/CoNLL04/BIO2id.json"
filename_relation2id = "data/CoNLL04/relation2id.json"

#training
is_use_n_char=False
epochs = 150
batch_size = 128
optimizer = Adam
save_model_file = "save_model/ner_model.weights"

#hyperparameters
hidden_size = 128
nb_head = 8
word_embed_size = 100
char_embed_size = 30
maxlen_sentence = 100
maxlen_word = 25
multi_layers = 4
embedding_dropout_prob = 0.25
nn_dropout_prob = 0.25
learning_rate = 1e-3
is_use_char_embedding = True

